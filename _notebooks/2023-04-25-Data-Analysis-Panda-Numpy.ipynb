{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Petite Pandas Data Analysis using Pandas and NumPy\n",
    "> A series of lessons based on the utilization of Pandas and NumPy to read and create interesting things with files and data. \n",
    "- toc: true"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis\n",
    "Predictive analysis is the use of statistical, data mining, and machine learning techniques to analyze current and historical data in order to make predictions about future events or behaviors. It involves identifying patterns and trends in data, and then using that information to forecast what is likely to happen in the future.\n",
    "\n",
    "Predictive analysis is used in a wide range of applications, from forecasting sales and demand, to predicting customer behavior, to detecting fraudulent transactions. It involves collecting and analyzing data from a variety of sources, including historical data, customer data, financial data, and social media data, among others.\n",
    "\n",
    "The process of predictive analysis typically involves the following steps:\n",
    "1. Defining the problem and identifying the relevant data sources\n",
    "2. Collecting and organizing data\n",
    "3. Exploring and analyzing the data to identify patterns and trends\n",
    "4. Selecting an appropriate model or algorithm to use for predictions\n",
    "5. Training and validating the model using historical data\n",
    "6. Using the model to make predictions on new data\n",
    "7. Monitoring and evaluating the performance of the model over time\n",
    "\n",
    "Predictive analysis can help organizations make more informed decisions, improve efficiency, and gain a competitive advantage by leveraging insights from data.\n",
    "\n",
    "It is most commonly used in retail, where workers try to predict which products would be most popular and try to advertise those products as much as possible, and also Healthcare, where algorithms analyze patterns and reveal prerequisites for diseases and suggest preventive treatment, predict the results of various treatments and choose the best option for each patient individually, and predict disease outbreaks and epidemics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Intro to NumPy and the features it consists\n",
    "\n",
    "Numpy, by definition, is the fundamental package for scientific computing in Python which can be used to perform mathematical operations, provide multidimensional array objects, and makes data analysis much easier. Numpy is very important and useful when it comes to data analysis, as it can easily use its features to complete and perform any mathematical operation, as well as analyze data files.\n",
    "\n",
    "If you don't already have numpy installed, you can do so using ```conda install numpy``` or ```pip install numpy```\n",
    "\n",
    "Once that is complete, to import numpy in your code, all you must do is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Using NumPy to create arrays\n",
    "An array is the central data structure of the NumPy library. They are used as containers which are able to store more than one item at the same time. Using the function ```np.array``` is used to create an array, in which you can create multidimensional arrays. \n",
    "\n",
    "Shown below is how to create a 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "print(a) \n",
    "# this creates a 1D array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How could you create a 3D array based on knowing how to make a 1D array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# create 3D array here\n",
    "a = np.array([[1, 2, 3] , [4, 5, 6] , [7, 8, 9]])\n",
    "print(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arrays can be printed in different ways, especially a more readable format. As we have seen, arrays are printed in rows and columns, but we can change that by using the ```reshape``` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "c = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(c.reshape(1, 9)) # organizes it all in a single line of output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code segment below, we can also specially select certain rows and columns from the array to further analyze selective data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 5]\n",
      " [7 8]]\n"
     ]
    }
   ],
   "source": [
    "print(c[1:, :2])\n",
    "# the 1: means \"start at row 1 and select all the remaining rows\"\n",
    "# the :2 means \"select the first two columns\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic array operations\n",
    "\n",
    "One of the most basic operations that can be performed on arrays is arithmetic operations. With numpy, it is very easy to perform arithmetic operations on arrays. You can add, subtract, miltiply and divide arrays, just like you would with regular numbers. When performing these operations, numpy applies the operation element-wise, meaning that it performs the operation on each element in the array separately. This makes it easy to perform operations on large amounts of data quickly and efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n",
      "[-3 -3 -3]\n",
      "[ 4 10 18]\n",
      "[0.25 0.4  0.5 ]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "print(a + b) # adds each value based on the column the integer is in\n",
    "print(a - b) # subtracts each value based on the column the integer is in\n",
    "print(a * b) # multiplies each value based on the column the integer is in\n",
    "print(a / b) # divides each value based on the column the integer is in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 54.59815003 148.4131591  403.42879349]\n",
      "[2.         2.23606798 2.44948974]\n"
     ]
    }
   ],
   "source": [
    "d = np.exp(b)\n",
    "e = np.sqrt(b)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the knowledge of how to use more advanced mathematical expressions than the basic 4 mathematical operations such as exponent and square root, now can you code how to calculate the 3 main trig expressions (sin, cos, tan), natural log, and log10 of a 1D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84147098 0.90929743 0.14112001]\n",
      "[ 0.54030231 -0.41614684 -0.9899925 ]\n",
      "[ 1.55740772 -2.18503986 -0.14254654]\n",
      "[0.         0.69314718 1.09861229]\n",
      "[0.         0.30103    0.47712125]\n"
     ]
    }
   ],
   "source": [
    "s = np.array([.25, .5, .75])\n",
    "# calculate sin\n",
    "print(np.sin(a))\n",
    "# calculate cos\n",
    "print(np.cos(a))\n",
    "# calculate tan\n",
    "print(np.tan(a))\n",
    "# calculate natural log\n",
    "print(np.log(a))\n",
    "# calculate log10\n",
    "print(np.log10(a))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data analysis using numpy\n",
    "Numpy provides a convenient and powerful way to perform data analysis tasks on large data sets. One of the most common tasks in data analysis is finding the mean, median, and standard deviation of a dataset. Numpy provides functions to perform these operations quickly and easily. The mean function calculates the average value of the data, while the median function calculates the middle value in the data. The standard deviation function calculates how spread out the data is from the mean. Additionally, numpy provides functions to find the minimum and maximum values in the data. These functions are very useful for gaining insight into the properties of large datasets and can be used for a wide range of data analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2\n",
      "12.0\n",
      "6.04648658313239\n",
      "2\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "data = np.array([2, 5, 12, 13, 19])\n",
    "print(np.mean(data)) # finds the mean of the dataset\n",
    "print(np.median(data)) # finds the median of the dataset\n",
    "print(np.std(data)) # finds the standard deviation of the dataset\n",
    "print(np.min(data)) # finds the min of the dataset\n",
    "print(np.max(data)) # finds the max of the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now from learning this, can you find a different way from how we can solve the sum or products of a dataset other than how we learned before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 1 and 2 is 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num1 = int(input(\"Entrar numbero uno\"))\n",
    "num2 = int(input(\"Entrar numbero dos\"))\n",
    "\n",
    "df = pd.DataFrame({'numberos': [num1, num2]})\n",
    "\n",
    "# calc sum\n",
    "result = df['numberos'].sum()\n",
    "\n",
    "# result\n",
    "print(f\"The sum of {num1} and {num2} is {result}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has the ability to handle CSV files, which are commonly used to store and exchange large datasets. By importing CSV files into numpy arrays, we can easily perform complex operations and analysis on the data, making numpy an essential tool for data scientists and researchers.\n",
    "\n",
    "```genfromtxt``` and ```loadtxt``` are two functions in the numpy library that can be used to read data from text files, including CSV files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```genfromtxt``` is a more advanced function that can be used to read text files that have more complex structures, including CSV files. ```genfromtxt``` can handle files that have missing or invalid data, or files that have columns of different data types. It can also be used to skip header lines or to read only specific columns from the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Name' ' Position' ' Average' ' HR' ' RBI' ' OPS' ' JerseyNumber']\n",
      " ['Manny Machado' ' 3B' ' .298' ' 32' ' 102' ' .897' ' 13']\n",
      " ['Fernando Tatis Jr' ' RF' ' .281' ' 42' ' 97' ' .975' ' 23']\n",
      " ['Juan Soto' ' LF' ' .242' ' 27' ' 62' ' .853' ' 22']\n",
      " ['Xander Bogaerts' ' SS' ' .307' ' 15' ' 73' ' .833' ' 2']\n",
      " ['Nelson Cruz' ' DH' ' .234' ' 10' ' 64' ' .651' ' 32']\n",
      " ['Matt Carpenter' ' DH' ' .305' ' 15' ' 37' ' 1.138' ' 14']\n",
      " ['Jake Cronenworth' ' 1B' ' .239' ' 17' ' 88' ' .722' ' 9']\n",
      " ['Ha-Seong Kim' ' 2B' ' .251' ' 11' ' 59' ' .708' ' 7']\n",
      " ['Trent Grisham' ' CF' ' .184' ' 17' ' 53' ' .626' ' 1']\n",
      " ['Luis Campusano' ' C' ' .250' ' 1' ' 5' ' .593' ' 12']\n",
      " ['Austin Nola' ' C' ' .251' ' 4' ' 40' ' .649' ' 26']\n",
      " ['Jose Azocar' ' OF' ' .257' ' 0' ' 10' ' .630' ' 28']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "padres = np.genfromtxt('files/padres.csv', delimiter=',', dtype=str, encoding='utf-8')\n",
    "# delimiter indicates that the data is separated into columns which is distinguished by commas\n",
    "# genfromtxt is used to read the csv file itself\n",
    "# dtype is used to have numpy automatically detect the data type in the csv file\n",
    "\n",
    "print(padres)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```loadtxt``` is a simpler function that can be used to read simple text files that have a regular structure, such as files that have only one type of data (such as all integers or all floats). ```loadtxt``` can be faster than ```genfromtxt``` because it assumes that the data in the file is well-structured and can be easily parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Name' ' Position' ' Average' ' HR' ' RBI' ' OPS' ' JerseyNumber']\n",
      " ['Manny Machado' ' 3B' ' .298' ' 32' ' 102' ' .897' ' 13']\n",
      " ['Fernando Tatis Jr' ' RF' ' .281' ' 42' ' 97' ' .975' ' 23']\n",
      " ['Juan Soto' ' LF' ' .242' ' 27' ' 62' ' .853' ' 22']\n",
      " ['Xander Bogaerts' ' SS' ' .307' ' 15' ' 73' ' .833' ' 2']\n",
      " ['Nelson Cruz' ' DH' ' .234' ' 10' ' 64' ' .651' ' 32']\n",
      " ['Matt Carpenter' ' DH' ' .305' ' 15' ' 37' ' 1.138' ' 14']\n",
      " ['Jake Cronenworth' ' 1B' ' .239' ' 17' ' 88' ' .722' ' 9']\n",
      " ['Ha-Seong Kim' ' 2B' ' .251' ' 11' ' 59' ' .708' ' 7']\n",
      " ['Trent Grisham' ' CF' ' .184' ' 17' ' 53' ' .626' ' 1']\n",
      " ['Luis Campusano' ' C' ' .250' ' 1' ' 5' ' .593' ' 12']\n",
      " ['Austin Nola' ' C' ' .251' ' 4' ' 40' ' .649' ' 26']\n",
      " ['Jose Azocar' ' OF' ' .257' ' 0' ' 10' ' .630' ' 28']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "padres = np.loadtxt('files/padres.csv', delimiter=',', dtype=str, encoding='utf-8')\n",
    "print(padres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in padres:\n",
    "    print(\",\".join(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "### What is Pandas\n",
    "Pandas is a Python library used for working with data sets. A python library is something  It has functions for analyzing, cleaning, exploring, and manipulating data.\n",
    "\n",
    "### Why Use Pandas?\n",
    "Pandas allows us to analyze big data and make conclusions based on statistical theories. Pandas can clean messy data sets, and make them readable and relevant. Also it is a part of data analysis, and data manipulation.\n",
    "\n",
    "### What Can Pandas Do?\n",
    "Pandas gives you answers about the data. Like:\n",
    "- Is there a correlation between two or more columns?\n",
    "- What is average value\n",
    "- Max value\n",
    "- Min value\n",
    "- How to load data \n",
    "- Delete data \n",
    "- Sort Data.\n",
    "\n",
    "Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called cleaning the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# What this does is it calls the python pandas library and this code segment is needed whenever incorporating pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DICTIONARIES AND DATASETS\n",
    "- One way you are able to manipulate a pandas data set is by creating a dictionary and calling it as seen with the dict data 1 and pd.dataframe which is a way to print the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      teams  standings\n",
      "0     BARCA          1\n",
      "1      REAL          2\n",
      "2  ATLETICO          3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = {\n",
    "  'teams': [\"BARCA\", \"REAL\", \"ATLETICO\"],\n",
    "  'standings': [1, 2, 3]\n",
    "}\n",
    "\n",
    "myvar = pd.DataFrame(data1)\n",
    "\n",
    "print(myvar)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and manipulaton of data through lists.\n",
    "- With pandas you can also organize the data which is one of its biggest perks, we call this indexing, this is when we define the first column in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math       1.0\n",
      "science    1.0\n",
      "pe         0.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Here is an example using lists and an index.\n",
    "import pandas as pd \n",
    "\n",
    "score = [5/5, 5/5, 1/5]\n",
    "\n",
    "myvar = pd.Series(score, index = [\"math\", \"science\", \"pe\"])\n",
    "\n",
    "print(myvar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Classes \n",
    "Within pandas the library consits of a lot of functions which allow you to manipulate datasets in lists dictionsaries and csv files here are some of the ones we are going to cover (hint: take notes on these)\n",
    "- Series\n",
    "    - Series of indexes, list, dict, etc\n",
    "- Index\n",
    "    - A specific element in a list\n",
    "- PeriodIndex\n",
    "    - Repeat within a certain index and ability to sort\n",
    "- DataframeGroupedBy\n",
    "    - Group seperate data within columns\n",
    "- Categorical\n",
    "    - Sets a category for items (good for repeats and organzation)\n",
    "- Time Stamp\n",
    "    - Display a specified time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PeriodIndex \n",
    "- This allows for a way to repeat data over time that it occurs as seen from january 2022 to december 2023. You can use Y for years, M for months, and D for days.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeriodIndex(['2022-06', '2022-07', '2022-08', '2022-09', '2022-10', '2022-11',\n",
      "             '2022-12', '2023-01', '2023-02', '2023-03', '2023-04', '2023-05',\n",
      "             '2023-06', '2023-07'],\n",
      "            dtype='period[M]')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "time = pd.period_range('2022-06', '2023-07', freq='M')\n",
    "\n",
    "\n",
    "print(time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement a way to show a period index from June 2022 to July 2023 in days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use period index to show - in days - June 2022 to 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Grouped By \n",
    "- This allows for you to organize your data and calculate the different functions such as\n",
    "- count(): returns the number of non-null values in each group.\n",
    "- sum(): returns the sum of values in each group.\n",
    "- mean(): returns the mean of values in each group.\n",
    "- min(): returns the minimum value in each group.\n",
    "- max(): returns the maximum value in each group.\n",
    "- median(): returns the median of values in each group.\n",
    "- var(): returns the variance of values in each group.\n",
    "- agg(): applies one or more functions to each group and returns a new DataFrame with the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method GroupBy.sum of <pandas.core.groupby.generic.DataFrameGroupBy object at 0x7ff84e0f2ce0>>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Category': ['E', 'F', 'E', 'F', 'E', 'F', 'E', 'F'],\n",
    "    'Value': [100, 250, 156, 255, 240, 303, 253, 3014]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "grouped = df.groupby('Category').sum #GUESS WHAT THIS WOULD BE IF WE WERE LOOKING FOR COMBINED TOTALS!()\n",
    "\n",
    "print(grouped)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical \n",
    "- This sets up a category for something and puts it within the categories and allows for better orginzation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yellow', 'orange', 'blue', 'yellow', 'orange']\n",
      "Categories (3, object): ['yellow', 'orange', 'blue']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "colors = pd.Categorical(['yellow', 'orange', 'blue', 'yellow', 'orange'], categories=['yellow', 'orange', 'blue'])\n",
    "\n",
    "print(colors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamp Class\n",
    "- This allows to display a single time which can be useful when working with datasets that deal with time allowing you to manipulate the time you do something and how you do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 02:00:00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "timing = pd.Timestamp('2023-02-05 02:00:00')\n",
    "\n",
    "print(timing)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV FILES!\n",
    "- A csv file contains data and within pandas you are able to call the function and you are able to manipulate the data with the certain data classes talked about above. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Name, Position, Average, HR, RBI, OPS, JerseyNumber\n",
    "- Manny Machado, 3B, .298, 32, 102, .897, 13\n",
    "- Tatis Jr, RF, .281, 42, 97, .975, 23\n",
    "- Juan Soto, LF, .242, 27, 62, .853, 22\n",
    "- Xanger Bogaerts, SS, .307, 15, 73, .833, 2\n",
    "- Nelson Cruz, DH, .234, 10, 64, .651, 32\n",
    "- Matt Carpenter, DH, .305, 15, 37, 1.138, 14\n",
    "- Cronezone, 1B, .239, 17, 88, .722, 9\n",
    "- Ha-Seong Kim, 2B, .251, 11, 59, .708, 7\n",
    "- Trent Grisham, CF, .184, 17, 53, .626, 1\n",
    "- Luis Campusano, C, .250, 1, 5, .593, 12\n",
    "- Austin Nola, C, .251, 4, 40, .649, 26\n",
    "- Jose Azocar, OF, .257, 0, 10, .630, 28\n",
    "\n",
    "QUESTION: WHAT DO YOU GUYS THINK THE INDEX FOR THIS WOULD BE?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you explain what is going on in this code segment below. (hint: define what ascending= false means, and df. head means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Duration Top 10---------\n",
      "                Name  Position   Average   HR   RBI    OPS   JerseyNumber\n",
      "3    Xander Bogaerts        SS     0.307   15    73  0.833              2\n",
      "8      Trent Grisham        CF     0.184   17    53  0.626              1\n",
      "4        Nelson Cruz        DH     0.234   10    64  0.651             32\n",
      "5     Matt Carpenter        DH     0.305   15    37  1.138             14\n",
      "0      Manny Machado        3B     0.298   32   102  0.897             13\n",
      "9     Luis Campusano         C     0.250    1     5  0.593             12\n",
      "2          Juan Soto        LF     0.242   27    62  0.853             22\n",
      "11       Jose Azocar        OF     0.257    0    10  0.630             28\n",
      "6   Jake Cronenworth        1B     0.239   17    88  0.722              9\n",
      "7       Ha-Seong Kim        2B     0.251   11    59  0.708              7\n",
      "--Duration Bottom 10------\n",
      "                 Name  Position   Average   HR   RBI    OPS   JerseyNumber\n",
      "4         Nelson Cruz        DH     0.234   10    64  0.651             32\n",
      "5      Matt Carpenter        DH     0.305   15    37  1.138             14\n",
      "0       Manny Machado        3B     0.298   32   102  0.897             13\n",
      "9      Luis Campusano         C     0.250    1     5  0.593             12\n",
      "2           Juan Soto        LF     0.242   27    62  0.853             22\n",
      "11        Jose Azocar        OF     0.257    0    10  0.630             28\n",
      "6    Jake Cronenworth        1B     0.239   17    88  0.722              9\n",
      "7        Ha-Seong Kim        2B     0.251   11    59  0.708              7\n",
      "1   Fernando Tatis Jr        RF     0.281   42    97  0.975             23\n",
      "10        Austin Nola         C     0.251    4    40  0.649             26\n",
      "Name,  Position,  Average,  HR,  RBI,  OPS,  JerseyNumber\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read csv and sort 'Duration' largest to smallest\n",
    "df = pd.read_csv('files/padres.csv').sort_values(by=['Name'], ascending=False)\n",
    "\n",
    "print(\"--Duration Top 10---------\")\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"--Duration Bottom 10------\")\n",
    "print(df.tail(10))\n",
    "print(', '.join(df.tail(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mode of the 'total_rooms' column is: 0    1527.0\n",
      "Name: total_rooms, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"./files/housing.csv\")\n",
    "\n",
    "\n",
    "mode_total_rooms = df['total_rooms'].mode()\n",
    "\n",
    "\n",
    "print(f\"The mode of the 'total_rooms' column is: {mode_total_rooms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             total_rooms  population  longitude\n",
      "total_rooms                                    \n",
      "2.0                  2.0         6.0          1\n",
      "6.0                  6.0         8.0          1\n",
      "8.0                  8.0        13.0          1\n",
      "11.0                11.0        24.0          1\n",
      "12.0                12.0        18.0          1\n",
      "...                  ...         ...        ...\n",
      "30450.0          30450.0      9419.0          1\n",
      "32054.0          32054.0     15507.0          1\n",
      "32627.0          32627.0     28566.0          1\n",
      "37937.0          37937.0     16122.0          1\n",
      "39320.0          39320.0     16305.0          1\n",
      "\n",
      "[5926 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./files/housing.csv\")\n",
    "\n",
    "\n",
    "grouped_df = df.groupby('total_rooms')\n",
    "\n",
    "\n",
    "agg_df = grouped_df.agg({'total_rooms': 'sum', 'population': 'mean', 'longitude': 'count'})\n",
    "\n",
    "# WHAT DO YOU GUYS THINK df.agg means in context of pandas and what does it stand for.\n",
    "\n",
    "\n",
    "print(agg_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Frontend Data Analysis Project\n",
    "[Link](https://paravsalaniwal.github.io/T3Project/DataAnalysisProject/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popcorn Hacks\n",
    "- Complete fill in the blanks for Predictive Analysis Numpy\n",
    "- Takes notes on Panda where it asks you to\n",
    "- Complete code segment tasks in Panda and Numpy\n",
    "\n",
    "# Main Hack\n",
    "- Make a data file - content is up to you, just make sure there are integer values - and print\n",
    "- Run Panda and Numpy commands\n",
    "    - Panda:\n",
    "        - Find Min and Max values\n",
    "        - Sort in order - can be order of least to greatest or vice versa\n",
    "        - Create a smaller dataframe and merge it with your data file\n",
    "    - Numpy:\n",
    "        -  Random number generation\n",
    "        - create a multi-dimensional array (multiple elements)\n",
    "        - create an array with linearly spaced intervals between values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   first_name  last_name  age  salary                  profession\n",
      "0     Orlando     Morgan   26  129306  Professional Border Hopper\n",
      "1      Evelyn       Weis   25  233457               Archaeologist\n",
      "2     Natalie     Harper   95  145172                Obesity Lord\n",
      "3     Harvard     Porter   55    6619                Hair Stylist\n",
      "4      Carter    Esteban   93  131439   Traditional Curry Chomper\n",
      "..        ...        ...  ...     ...                         ...\n",
      "95       Jade        Cox   22  182905    Crime Scene Investigator\n",
      "96       Abby   The IIII   29  131219                     Surgeon\n",
      "97        Max  The IIIII   88  115416                Hair Stylist\n",
      "98     Sleepy   Gonzalez   85   20450                        Chef\n",
      "99       Liam    The III   49  198129          Professional Gamer\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "first_names = ['Orlando', 'Soham', 'Colin', 'James', 'Ethan', 'Emily', 'Harvard', 'Joe', 'Sleepy', 'Sleepy Joe', 'Mary', 'Your Mom', 'Collin', 'Max', 'Bartholomew', 'Joel', 'Ava', 'Oliver', 'Charlotte', 'Lucas', 'Harper', 'Mason', 'Amelia', 'Evelyn', 'Logan', 'Ella', 'Joseph', 'Liam', 'Connor', 'Abby', 'Austin', 'Avery', 'Bryce', 'Camila', 'Carter', 'Charlotte', 'Eli', 'Ella', 'Emma', 'Grace', 'Hazel', 'Isaac', 'Jade', 'Jaxon', 'Jocelyn', 'Levi', 'Lila', 'Liliana', 'Mia', 'Mila', 'Natalie', 'Oliver', 'Piper', 'Sebastian', 'Jillian',]\n",
    "last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Carcamo', 'Weis', 'Kamat', 'Joe', 'Biden', 'Ward', 'Campbell', 'Gonzalez', 'Bailey', 'Bennett', 'Wong', 'Perry', 'Ross', 'Dixon', 'Morgan', 'Owens', 'Harris', 'Lopez', 'Foster', 'Chambers', 'Hayes', 'Porter', 'Peters', 'Sullivan', 'Wright', 'Edwards', 'Mitchell', 'Esteban', 'Cox', 'Hill', 'Harper', 'Ceja', 'Jr', 'The III', 'The II', 'The IIII', 'The IIIII']\n",
    "professions = ['Doctor', 'Heart Seller', 'Professional Coach', 'Lifeguard', 'Astronaut', 'Robotics Engineer', 'Artificial Intelligence Developer', 'Magician', 'Firefighter', 'Astrologer', 'Barista', 'Psychiatrist', 'Crime Scene Investigator', 'Private Investigator', 'Dog Walker', 'Chocolatier', 'Cartoonist', 'Meteorologist', 'Circus Performer', 'Graphic Designer', 'Fashion Designer', 'Musician', 'Professional Gamer', 'Baker', 'Stand-up Comedian', 'Movie Director', 'Gardener', 'Event Planner', 'Archaeologist', 'Translator', 'Social Media Influencer', 'Fitness Trainer', 'Mechanic', 'Chef', 'Hair Stylist', 'Mortician', 'Wine Sommelier', 'Surgeon', 'Yoga Instructor', 'Author', 'Interior Designer', 'Tattoo Artist', 'Pilot', 'Magistrate', 'Historian', 'Art Dealer', 'Cartographer', 'Acrobat', 'Paranormal Investigator', 'Professional Border Hopper', 'Taco Muncher', 'Horchata Slurper', 'Traditional Curry Chomper', 'Professional \"Mom\" investigator', 'School Shooter', 'Obesity Lord', ]\n",
    "\n",
    "# Create a DataFrame with randomized first names, last names, hours of work, and professions\n",
    "data = []\n",
    "for i in range(100):\n",
    "    data.append({\n",
    "        'first_name': random.choice(first_names),\n",
    "        'last_name': random.choice(last_names),\n",
    "        'age': random.randint(1, 120),\n",
    "        'salary': random.randint(-20000, 250000),\n",
    "        'profession': random.choice(professions)\n",
    "    })\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('goofy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max age - 120\n",
      "Min age - 2\n",
      "Average age - 64.42\n",
      "Max salary - 247410\n",
      "Min salary - -16787\n",
      "Average salary - 107696.13\n",
      "Most common profession - Interior Designer\n",
      "Most common first name - Emily\n",
      "Most common last name - Mitchell\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('goofy.csv')\n",
    "\n",
    "max_age = df['age'].max()\n",
    "min_age = df['age'].min()\n",
    "avg_age = df['age'].mean()\n",
    "\n",
    "max_salary = df['salary'].max()\n",
    "min_salary = df['salary'].min()\n",
    "avg_salary = df['salary'].mean()\n",
    "\n",
    "most_common_profession = df['profession'].mode()[0]\n",
    "most_common_fn = df['first_name'].mode()[0]\n",
    "most_common_ln = df['last_name'].mode()[0]\n",
    "\n",
    "print(f\"Max age - {max_age}\")\n",
    "print(f\"Min age - {min_age}\")\n",
    "print(f\"Average age - {avg_age:.2f}\")\n",
    "print(f\"Max salary - {max_salary}\")\n",
    "print(f\"Min salary - {min_salary}\")\n",
    "print(f\"Average salary - {avg_salary:.2f}\")\n",
    "print(f\"Most common profession - {most_common_profession}\")\n",
    "print(f\"Most common first name - {most_common_fn}\")\n",
    "print(f\"Most common last name - {most_common_ln}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 36 46 47 46 25 33 44 37 30]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random_list = [random.randint(1, 50) for i in range(10)]\n",
    "\n",
    "array = np.array(random_list)\n",
    "\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "max_num = np.amax(array)\n",
    "\n",
    "square = int(np.sqrt(max_num)) ** 2\n",
    "\n",
    "triple_d_array = np.zeros((square, square, square))\n",
    "\n",
    "print(triple_d_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00000000e+00 2.14339299e-05 4.28678598e-05 ... 7.07319687e-04\n",
      "   7.28753617e-04 7.50187547e-04]\n",
      "  [7.71621477e-04 7.93055407e-04 8.14489337e-04 ... 1.47894116e-03\n",
      "   1.50037509e-03 1.52180902e-03]\n",
      "  [1.54324295e-03 1.56467688e-03 1.58611081e-03 ... 2.25056264e-03\n",
      "   2.27199657e-03 2.29343050e-03]\n",
      "  ...\n",
      "  [2.54635087e-02 2.54849427e-02 2.55063766e-02 ... 2.61708284e-02\n",
      "   2.61922624e-02 2.62136963e-02]\n",
      "  [2.62351302e-02 2.62565641e-02 2.62779981e-02 ... 2.69424499e-02\n",
      "   2.69638838e-02 2.69853178e-02]\n",
      "  [2.70067517e-02 2.70281856e-02 2.70496195e-02 ... 2.77140714e-02\n",
      "   2.77355053e-02 2.77569392e-02]]\n",
      "\n",
      " [[2.77783732e-02 2.77998071e-02 2.78212410e-02 ... 2.84856929e-02\n",
      "   2.85071268e-02 2.85285607e-02]\n",
      "  [2.85499946e-02 2.85714286e-02 2.85928625e-02 ... 2.92573143e-02\n",
      "   2.92787483e-02 2.93001822e-02]\n",
      "  [2.93216161e-02 2.93430500e-02 2.93644840e-02 ... 3.00289358e-02\n",
      "   3.00503697e-02 3.00718037e-02]\n",
      "  ...\n",
      "  [5.32418819e-02 5.32633158e-02 5.32847498e-02 ... 5.39492016e-02\n",
      "   5.39706355e-02 5.39920694e-02]\n",
      "  [5.40135034e-02 5.40349373e-02 5.40563712e-02 ... 5.47208231e-02\n",
      "   5.47422570e-02 5.47636909e-02]\n",
      "  [5.47851249e-02 5.48065588e-02 5.48279927e-02 ... 5.54924445e-02\n",
      "   5.55138785e-02 5.55353124e-02]]\n",
      "\n",
      " [[5.55567463e-02 5.55781803e-02 5.55996142e-02 ... 5.62640660e-02\n",
      "   5.62854999e-02 5.63069339e-02]\n",
      "  [5.63283678e-02 5.63498017e-02 5.63712357e-02 ... 5.70356875e-02\n",
      "   5.70571214e-02 5.70785554e-02]\n",
      "  [5.70999893e-02 5.71214232e-02 5.71428571e-02 ... 5.78073090e-02\n",
      "   5.78287429e-02 5.78501768e-02]\n",
      "  ...\n",
      "  [8.10202551e-02 8.10416890e-02 8.10631229e-02 ... 8.17275748e-02\n",
      "   8.17490087e-02 8.17704426e-02]\n",
      "  [8.17918765e-02 8.18133105e-02 8.18347444e-02 ... 8.24991962e-02\n",
      "   8.25206302e-02 8.25420641e-02]\n",
      "  [8.25634980e-02 8.25849319e-02 8.26063659e-02 ... 8.32708177e-02\n",
      "   8.32922516e-02 8.33136856e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[9.16686314e-01 9.16707748e-01 9.16729182e-01 ... 9.17393634e-01\n",
      "   9.17415068e-01 9.17436502e-01]\n",
      "  [9.17457936e-01 9.17479370e-01 9.17500804e-01 ... 9.18165256e-01\n",
      "   9.18186690e-01 9.18208123e-01]\n",
      "  [9.18229557e-01 9.18250991e-01 9.18272425e-01 ... 9.18936877e-01\n",
      "   9.18958311e-01 9.18979745e-01]\n",
      "  ...\n",
      "  [9.42149823e-01 9.42171257e-01 9.42192691e-01 ... 9.42857143e-01\n",
      "   9.42878577e-01 9.42900011e-01]\n",
      "  [9.42921445e-01 9.42942879e-01 9.42964313e-01 ... 9.43628764e-01\n",
      "   9.43650198e-01 9.43671632e-01]\n",
      "  [9.43693066e-01 9.43714500e-01 9.43735934e-01 ... 9.44400386e-01\n",
      "   9.44421820e-01 9.44443254e-01]]\n",
      "\n",
      " [[9.44464688e-01 9.44486122e-01 9.44507555e-01 ... 9.45172007e-01\n",
      "   9.45193441e-01 9.45214875e-01]\n",
      "  [9.45236309e-01 9.45257743e-01 9.45279177e-01 ... 9.45943629e-01\n",
      "   9.45965063e-01 9.45986497e-01]\n",
      "  [9.46007931e-01 9.46029364e-01 9.46050798e-01 ... 9.46715250e-01\n",
      "   9.46736684e-01 9.46758118e-01]\n",
      "  ...\n",
      "  [9.69928196e-01 9.69949630e-01 9.69971064e-01 ... 9.70635516e-01\n",
      "   9.70656950e-01 9.70678384e-01]\n",
      "  [9.70699818e-01 9.70721252e-01 9.70742686e-01 ... 9.71407137e-01\n",
      "   9.71428571e-01 9.71450005e-01]\n",
      "  [9.71471439e-01 9.71492873e-01 9.71514307e-01 ... 9.72178759e-01\n",
      "   9.72200193e-01 9.72221627e-01]]\n",
      "\n",
      " [[9.72243061e-01 9.72264495e-01 9.72285929e-01 ... 9.72950380e-01\n",
      "   9.72971814e-01 9.72993248e-01]\n",
      "  [9.73014682e-01 9.73036116e-01 9.73057550e-01 ... 9.73722002e-01\n",
      "   9.73743436e-01 9.73764870e-01]\n",
      "  [9.73786304e-01 9.73807738e-01 9.73829172e-01 ... 9.74493623e-01\n",
      "   9.74515057e-01 9.74536491e-01]\n",
      "  ...\n",
      "  [9.97706569e-01 9.97728003e-01 9.97749437e-01 ... 9.98413889e-01\n",
      "   9.98435323e-01 9.98456757e-01]\n",
      "  [9.98478191e-01 9.98499625e-01 9.98521059e-01 ... 9.99185511e-01\n",
      "   9.99206945e-01 9.99228379e-01]\n",
      "  [9.99249812e-01 9.99271246e-01 9.99292680e-01 ... 9.99957132e-01\n",
      "   9.99978566e-01 1.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "linear_array = np.linspace(0, 1, num=square ** 3).reshape(square, square, square)\n",
    "\n",
    "print(linear_array)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading\n",
    "The grading will be binary - all or nothing; no partial credit\n",
    "- 0.3 for all the popcorn hacks\n",
    "> - done-erino\n",
    "- 0.6 for the main hack - CSV file\n",
    "> - Picasso is finished\n",
    "- 0.1 for going above and beyond in the main hack\n",
    "> - I mean look at the picasso"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
